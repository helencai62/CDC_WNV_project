{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Referenced 6.02-lesson-bagging-rfs for below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating decision tree model with combined + cleaned dataset: train_merge_all.csv, test_merge_all.csv\n",
    "train = pd.read_csv('train_merge_all.csv')\n",
    "test = pd.read_csv('test_merge_all.csv')\n",
    "\n",
    "train = train.drop(['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1'], axis = 1)\n",
    "test = test.drop(['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10506, 28) (116293, 28)\n",
      "\n",
      "\n",
      "Index(['Date', 'Species', 'Trap', 'Longitude', 'Latitude', 'Tmax', 'Tmin',\n",
      "       'Tavg', 'Depart', 'DewPoint', 'WetBulb', 'Heat', 'Cool', 'Sunrise',\n",
      "       'Sunset', 'CodeSum', 'Depth', 'Water1', 'SnowFall', 'PrecipTotal',\n",
      "       'StnPressure', 'SeaLevel', 'ResultSpeed', 'ResultDir', 'AvgSpeed',\n",
      "       'DaysFromSpray', 'LogDays', 'SprayEffect'],\n",
      "      dtype='object') \n",
      "\n",
      " Index(['Date', 'Species', 'Trap', 'Longitude', 'Latitude', 'Tmax', 'Tmin',\n",
      "       'Tavg', 'Depart', 'DewPoint', 'WetBulb', 'Heat', 'Cool', 'Sunrise',\n",
      "       'Sunset', 'CodeSum', 'Depth', 'Water1', 'SnowFall', 'PrecipTotal',\n",
      "       'StnPressure', 'SeaLevel', 'ResultSpeed', 'ResultDir', 'AvgSpeed',\n",
      "       'DaysFromSpray', 'LogDays', 'SprayEffect'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#check train + test set variable sets: these do not include target Y = WnvPresent (0/1)\n",
    "print(train.shape, test.shape)\n",
    "print('\\n')\n",
    "print(train.columns, '\\n\\n', test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Tmax</th>\n",
       "      <th>Tmin</th>\n",
       "      <th>Tavg</th>\n",
       "      <th>Depart</th>\n",
       "      <th>DewPoint</th>\n",
       "      <th>WetBulb</th>\n",
       "      <th>Heat</th>\n",
       "      <th>Cool</th>\n",
       "      <th>...</th>\n",
       "      <th>CodeSum_['RA', 'BR', 'HZ', 'TS', 'TSRA']</th>\n",
       "      <th>CodeSum_['RA', 'BR', 'HZ', 'TSRA', 'VCTS']</th>\n",
       "      <th>CodeSum_['RA', 'BR', 'TS', 'TSRA']</th>\n",
       "      <th>CodeSum_['RA', 'SQ', 'BR', 'HZ', 'TS', 'TSRA']</th>\n",
       "      <th>CodeSum_['RA', 'TS', 'TSRA']</th>\n",
       "      <th>CodeSum_['RA', 'TSRA']</th>\n",
       "      <th>CodeSum_['RA']</th>\n",
       "      <th>CodeSum_['TS', 'RA', 'TSRA']</th>\n",
       "      <th>CodeSum_['VCTS', 'BR', 'RA', 'TSRA']</th>\n",
       "      <th>CodeSum_[]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-87.800991</td>\n",
       "      <td>41.95469</td>\n",
       "      <td>82.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>73.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>65.2</td>\n",
       "      <td>68.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-87.800991</td>\n",
       "      <td>41.95469</td>\n",
       "      <td>82.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>73.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>65.2</td>\n",
       "      <td>68.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-87.800991</td>\n",
       "      <td>41.95469</td>\n",
       "      <td>82.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>73.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>65.2</td>\n",
       "      <td>68.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-87.800991</td>\n",
       "      <td>41.95469</td>\n",
       "      <td>82.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>73.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>65.2</td>\n",
       "      <td>68.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-87.800991</td>\n",
       "      <td>41.95469</td>\n",
       "      <td>82.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>73.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>65.2</td>\n",
       "      <td>68.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Longitude  Latitude  Tmax  Tmin  Tavg  Depart  DewPoint  WetBulb  Heat  \\\n",
       "0 -87.800991  41.95469  82.3  64.7  73.7     7.3      65.2     68.2   0.0   \n",
       "1 -87.800991  41.95469  82.3  64.7  73.7     7.3      65.2     68.2   0.0   \n",
       "2 -87.800991  41.95469  82.3  64.7  73.7     7.3      65.2     68.2   0.0   \n",
       "3 -87.800991  41.95469  82.3  64.7  73.7     7.3      65.2     68.2   0.0   \n",
       "4 -87.800991  41.95469  82.3  64.7  73.7     7.3      65.2     68.2   0.0   \n",
       "\n",
       "   Cool     ...      CodeSum_['RA', 'BR', 'HZ', 'TS', 'TSRA']  \\\n",
       "0   8.7     ...                                             0   \n",
       "1   8.7     ...                                             0   \n",
       "2   8.7     ...                                             0   \n",
       "3   8.7     ...                                             0   \n",
       "4   8.7     ...                                             0   \n",
       "\n",
       "   CodeSum_['RA', 'BR', 'HZ', 'TSRA', 'VCTS']  \\\n",
       "0                                           0   \n",
       "1                                           0   \n",
       "2                                           0   \n",
       "3                                           0   \n",
       "4                                           0   \n",
       "\n",
       "   CodeSum_['RA', 'BR', 'TS', 'TSRA']  \\\n",
       "0                                   0   \n",
       "1                                   0   \n",
       "2                                   0   \n",
       "3                                   0   \n",
       "4                                   0   \n",
       "\n",
       "   CodeSum_['RA', 'SQ', 'BR', 'HZ', 'TS', 'TSRA']  \\\n",
       "0                                               0   \n",
       "1                                               0   \n",
       "2                                               0   \n",
       "3                                               0   \n",
       "4                                               0   \n",
       "\n",
       "   CodeSum_['RA', 'TS', 'TSRA']  CodeSum_['RA', 'TSRA']  CodeSum_['RA']  \\\n",
       "0                             0                       0               0   \n",
       "1                             0                       0               0   \n",
       "2                             0                       0               0   \n",
       "3                             0                       0               0   \n",
       "4                             0                       0               0   \n",
       "\n",
       "   CodeSum_['TS', 'RA', 'TSRA']  CodeSum_['VCTS', 'BR', 'RA', 'TSRA']  \\\n",
       "0                             0                                     0   \n",
       "1                             0                                     0   \n",
       "2                             0                                     0   \n",
       "3                             0                                     0   \n",
       "4                             0                                     0   \n",
       "\n",
       "   CodeSum_[]  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "\n",
       "[5 rows x 312 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#turn text features (col CodeSum from weather data) into categories\n",
    "train = pd.get_dummies(train)\n",
    "train.head()\n",
    "\n",
    "test = pd.get_dummies(test)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'target.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a96cce378d9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'target.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dsi/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dsi/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dsi/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dsi/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dsi/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'target.csv' does not exist"
     ]
    }
   ],
   "source": [
    "#Set X (variable) and y (target) datasets for training data\n",
    "X = train\n",
    "\n",
    "y = pd.read_csv('target.csv')\n",
    "y\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    9955\n",
      "1     551\n",
      "Name: WnvPresent, dtype: int64\n",
      "0    0.947554\n",
      "1    0.052446\n",
      "Name: WnvPresent, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Set baseline accuracy\n",
    "print(y.value_counts())\n",
    "baseline = y.value_counts() / len(y)\n",
    "print(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7354, 308) (7354,)\n",
      "(3152, 308) (3152,)\n"
     ]
    }
   ],
   "source": [
    "#train-test-split training set: 70/30 split, stratify y to preseve same distro seen in overall training set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, stratify = y, test_size = 0.3)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.9843622518357357\n",
      "test: 0.9238578680203046\n"
     ]
    }
   ],
   "source": [
    "#instantiate, fit + score Decision Tree classifier\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "tree.fit(X_train, y_train)\n",
    "print('train:', tree.score(X_train, y_train))\n",
    "print('test:', tree.score(X_test, y_test))    #shows slight bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.984226271416916\n",
      "test: 0.9359137055837563\n"
     ]
    }
   ],
   "source": [
    "#bagging classifier with DecisionTreeClassifier\n",
    "bag = BaggingClassifier(random_state = 42, base_estimator = DecisionTreeClassifier(), n_estimators = 100)\n",
    "bag.fit(X_train, y_train)\n",
    "print('train:', bag.score(X_train, y_train))\n",
    "print('test:', bag.score(X_test, y_test))    #shows slight bias, can tune hyperparameter n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.9475115583355996\n",
      "train: {'base_estimator__max_depth': 1, 'base_estimator__min_samples_split': 2, 'n_estimators': 1}\n"
     ]
    }
   ],
   "source": [
    "#bagging classifier with DecisionTreeClassifier tuning for hyperparameters\n",
    "bag = BaggingClassifier(random_state=42, base_estimator = DecisionTreeClassifier())\n",
    "bag_params = {\n",
    "    'base_estimator__max_depth': range(1, 10),    #iter1: range(2, 4)\n",
    "    'base_estimator__min_samples_split': range(2, 10),    #iter1: range(2, 5)\n",
    "    'n_estimators': [1, 2, 5, 7, 9, 10]    #iter1: [10, 20, 50, 75, 100]\n",
    "}\n",
    "\n",
    "\n",
    "gs = GridSearchCV(bag, param_grid=bag_params)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print('train:', gs.best_score_)\n",
    "print('train:', gs.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gs.best_params_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.9475115583355996\n",
      "test: 0.9476522842639594\n"
     ]
    }
   ],
   "source": [
    "#try bagging classifier with best_params from tuning\n",
    "best = BaggingClassifier(random_state = 42, \n",
    "                         base_estimator = DecisionTreeClassifier(\n",
    "                             max_depth = gs.best_params_['base_estimator__max_depth'], \n",
    "                             min_samples_split = gs.best_params_['base_estimator__min_samples_split']), \n",
    "                         n_estimators = gs.best_params_['n_estimators'])\n",
    "\n",
    "best.fit(X_train, y_train)\n",
    "print('train:', best.score(X_train, y_train))\n",
    "print('test:', best.score(X_test, y_test))    #better bias-variance tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.9772912700571118\n",
      "test: 0.9406725888324873\n"
     ]
    }
   ],
   "source": [
    "#Random Forest classifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "print('train:', rf.score(X_train, y_train))\n",
    "print('test:', rf.score(X_test, y_test))    #biased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.9843622518357357\n",
      "test: 0.9441624365482234\n"
     ]
    }
   ],
   "source": [
    "#ExtraTrees classifier\n",
    "et = ExtraTreesClassifier()\n",
    "et.fit(X_train, y_train)\n",
    "print('train:', et.score(X_train, y_train))\n",
    "print('test:', et.score(X_test, y_test))    #biased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7354, 308)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.9479194995920588\n",
      "test: 0.9486040609137056\n"
     ]
    }
   ],
   "source": [
    "#comparing against LogReg model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "print('train:', lr.score(X_train, y_train))\n",
    "print('test:', lr.score(X_test, y_test))    #very similar to results from bagged DecisionTree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.947554\n",
       "1    0.052446\n",
       "Name: WnvPresent, dtype: float64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best test set score for DT: bagging with decisiontree classifier\n",
    "    #gridsearch for hyperparameters\n",
    "#on par with score from LogReg\n",
    "\n",
    "#both on par with baseline, not performing particularly better\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict target WnvPresent in test_merge_all.csv\n",
    "    #1. Bagged/tuned DT predict\n",
    "        #take unique values of CodeSum and one-hot encode 1 if value in CodeSum col\n",
    "    #2. LogReg predict\n",
    "        #take unique values of CodeSum and one-hot encode 1 if value in CodeSum col\n",
    "    #3. LogReg predict \n",
    "        #simplified\n",
    "        #w/o CodeSum, Date, Trap, + unspecified species in test for type of mosquito\n",
    "            #pd.get_dummies returns different number of cols in train vs test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Longitude', 'Latitude', 'Tmax', 'Tmin', 'Tavg', 'Depart', 'DewPoint', 'WetBulb', 'Heat', 'Cool', 'Sunrise', 'Sunset', 'Depth', 'Water1', 'SnowFall', 'PrecipTotal', 'StnPressure', 'SeaLevel', 'ResultSpeed', 'ResultDir', 'AvgSpeed', 'DaysFromSpray', 'LogDays', 'SprayEffect', 'Species_CULEX ERRATICUS', 'Species_CULEX PIPIENS', 'Species_CULEX PIPIENS/RESTUANS', 'Species_CULEX RESTUANS', 'Species_CULEX SALINARIUS', 'Species_CULEX TARSALIS', 'Species_CULEX TERRITANS'] (10506, 31)\n",
      "(7354, 31) (7354,)\n",
      "(3152, 31) (3152,)\n",
      "train: 0.9475115583355996\n",
      "test: 0.9476522842639594\n"
     ]
    }
   ],
   "source": [
    "#3. LogReg model: simplified\n",
    "X = pd.read_csv('train_merge_all.csv')\n",
    "X = X.drop(['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1', 'Date', 'CodeSum', 'Trap'], axis = 1)\n",
    "X = pd.get_dummies(X)\n",
    "print(list(X.columns), X.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, stratify =  y, test_size = 0.3)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "print('train:', lr.score(X_train, y_train))\n",
    "print('test:', lr.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Longitude', 'Latitude', 'Tmax', 'Tmin', 'Tavg', 'Depart', 'DewPoint', 'WetBulb', 'Heat', 'Cool', 'Sunrise', 'Sunset', 'Depth', 'Water1', 'SnowFall', 'PrecipTotal', 'StnPressure', 'SeaLevel', 'ResultSpeed', 'ResultDir', 'AvgSpeed', 'DaysFromSpray', 'LogDays', 'SprayEffect', 'Species_CULEX ERRATICUS', 'Species_CULEX PIPIENS', 'Species_CULEX PIPIENS/RESTUANS', 'Species_CULEX RESTUANS', 'Species_CULEX SALINARIUS', 'Species_CULEX TARSALIS', 'Species_CULEX TERRITANS'] (116293, 31)\n"
     ]
    }
   ],
   "source": [
    "#3. predict target\n",
    "X = pd.read_csv('test_merge_all.csv')\n",
    "X = X.drop(['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1', 'Date', 'CodeSum', 'Trap'], axis = 1)\n",
    "X = pd.get_dummies(X).drop(['Species_UNSPECIFIED CULEX'], axis = 1)\n",
    "print(list(X.columns), X.shape)\n",
    "\n",
    "y_pred = lr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input target values to sample submission format + save to_csv\n",
    "X['WnvPresent'] = y_pred\n",
    "X = X.loc[:, ['WnvPresent']]\n",
    "X.index += 1    #reset index to start at 1\n",
    "X.index.names = ['Id']\n",
    "\n",
    "X.to_csv('sample1hc.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    116293\n",
       "Name: WnvPresent, dtype: int64"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['WnvPresent'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict y value for test_merge_all.csv\n",
    "#train_checker = pd.get_dummies(train['CodeSum']).columns\n",
    "#test_checker = pd.get_dummies(test['CodeSum']).columns\n",
    "\n",
    "#i = 0\n",
    "#for train_col in train_checker:\n",
    "    #print(train_col)\n",
    "#    i += 1\n",
    "#    for test_col in test_checker:\n",
    "#        print(train_col, test_col)\n",
    "#        if train_col == test_col:\n",
    "#            print (i, 'yes')\n",
    "#        else:\n",
    "#            print (i, 'no') \n",
    "    \n",
    "#lr.predict(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
